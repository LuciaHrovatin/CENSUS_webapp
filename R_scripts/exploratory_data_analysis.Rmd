# Explorative Data Analysis (EDA)

### Import libraries
```{r message=FALSE, warning=FALSE}

library(ggplot2)
library(ggcorrplot)
library(cowplot)
library(PerformanceAnalytics)
library(GGally)
library(knitr)
library(kableExtra)

```

### Import final and final_individual tables
```{r}

final <- read.csv("/Users/elypa/Downloads/final.csv")
final_individual <- read.csv("/Users/elypa/Downloads/final_individual.csv")

```

### Tidy up and remove unuseful columns ("id" and "area5")
```{r}

final <- final[-c(1, 10)]
final <- na.omit(final)

final_individual <- final[-c(1, 10)]
final_individual <- na.omit(final_individual)

```

### Compute variables correlation matrix

```{r message=FALSE, warning=FALSE}

cor(final)
cor(final_individual)

```

### Plot correlation matrix
```{r fig.height=9, fig.width=12, message=FALSE, warning=FALSE}

# final
# Correlation matrix
corr_final = round(cor(final), 1)

# Plot
final_corplot <- ggcorrplot(corr_final, hc.order = TRUE, 
                            type = "lower", 
                            lab = TRUE, 
                            lab_size = 3, 
                            method="circle", 
                            colors = c("tomato2", "white", "springgreen3"), 
                            title="final variable corelation", 
                            ggtheme=theme_bw)

#final_individual
# Correlation matrix
corr_final_indiv = round(cor(final_individual), 1)

# Plot
final_indv_corplot <- ggcorrplot(corr_final_indiv, hc.order = TRUE, 
                                 type = "lower", 
                                 lab = TRUE, 
                                 lab_size = 3, 
                                 method="circle", 
                                 colors = c("tomato2", "white", "springgreen3"), 
                                 title="final_individual variable corelation", 
                                 ggtheme=theme_bw)

plot_grid(final_corplot, final_indv_corplot)

```

As the correlographs show, the Exploratory Data Analysis (EDA) detected several high Pearson correlation coefficients. In particular, a $\rho > |\pm 0.6|$ is detected between: <b>
**staciv-anasc**, **staciv-sex**, **anasc-ireg**, and **ireg-sex** in both datasets. <b>
A strong negative correlation ($\rho = -1$) characterises the couple **sex-anasc**. <b>
These results can already cut out some classification methods having the assumption of independence between predictors.

### Compute more informative matrices
```{r fig.height=16, fig.width=16, message=FALSE, warning=FALSE}

final_chart <- ggpairs(final,            
                       lower = list(continuous = wrap("points", alpha = 0.5)), 
                       diag = list(discrete="barDiag", continuous = wrap("densityDiag", alpha=0.5 ))
                       )

final_chart


```

```{r fig.height=16, fig.width=16, message=FALSE, warning=FALSE}

final_indiv_chart <- ggpairs(final_individual,            
                       lower = list(continuous = wrap("points", alpha = 0.5)), 
                       diag = list(discrete="barDiag", continuous = wrap("densityDiag", alpha=0.5 ))
                       )

final_indiv_chart

```

The variables contained in those datasets are:<b>
- *nquest* and *nord*: both integer numbers. nquest (household ID) represents the primary key to merge household level. In order to merge individual level information it must be considered together with nord (ID of each household member).<b>
- *sex*: define males as 1 and females as 2.<b>
- *anasc*: year of birth of the respondent
- *staciv*: marital status which is inserted as integer number ranging from 1 to 6. Specifically, it identifies: <b>
1 = celibe/nubile, 2 = convivente, 3 = Sposato/a, 4 = Vedovo/a, 5 Separato/a, and 6 Divorziato/a.
- *ireg*: integer number (1-20) reporting the NUTS2 codes, meaning the numbers associated with the Italian regions. In particular: 

```{r echo=FALSE, message=FALSE, warning=FALSE}

regions <- c("Piemonte", "Valle d'Aosta", "Lombardia",
            "Trentino Alto Adige", "Veneto",
            "Friuli Venezia Giulia","Liguria", 
            "Emilia Romagna", "Toscana", "Umbria",
            "Marche", "Lazio", "Abruzzo", "Molise",
            "Campania", "Puglia",
            "Basilicata", "Calabria","Sicilia", "Sardegna")
numbers <- seq(1,20)

association <- data.frame("Region"=regions,"NUTS2"=numbers)

knitr::kable(association, caption = "Regions and corresponding NUTS2 code")

```


The variables' density functions highlight an absence of normality. Therefore, they do not satisfy the assumptions of statistical learning methods such as LDA (Linear Discriminant Analysis) and QDA (Quadratic Discriminant Analysis). Indeed, the assumptions that must be satisfied in LDA and QDA:

* **Multivariate normality**: the predictors taken into consideration should follow a gaussian distribution for each grouping variable level.

* **Homoscedasticity**: LDA assumes an equal variance among the different predictor variables, while in QDA the assumption of a common variance/covariance matrix across classes does not hold.

* **Multicollinearity**: the predictor variables should not be  significantly correlated

As seen above, these assumptions are not met and they are expected to perform poorly or at least worse than other classification algorithms, such as $k$-NN and Random Forest.
